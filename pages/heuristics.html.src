<title>enclone heuristics</title>

<body>

<br>
<a href="../../index.html#help">
<img src="../../img/enclone_banner.png" alt="enclone banner" title="enclone banner" width=100% />
</a>

<h1>enclone heuristics</h1>

<p>This page is a start in describing the heuristics that #enclone uses.  It will be gradually
expanded.  See also <a href="../../pages/auto/help.how.html">enclone help how</a>
and <a href="../../pages/auto/help.special.html">enclone help special</a>.  
The content here is geeky and technical.
</p>

<hr>

<p>
<b>Clonotype chain grouping.</b>
After exact subclonotypes have been grouped into clonotypes, we decide which chains from which 
exact subclonotypes are placed in the same column of the table for the clonotype.  While in most
particular instances the answer is "obvious", the general problem is complicated.  We proceed by
"joining" chains, i.e. deciding that they will go in the same column.  There are several steps:
<ol>
<li>At the earlier point in the algorithm where we decide that two exact subclonotypes go in the 
same clonotype, we align a heavy or TRB chain from each (one from each exact subclonotype) to the
other, and likewise for the light or TRA chains.  This defines a correspondence between chains,
and at the subsequent point when we generate clonotype tables, this information is carried forward 
to join chains.</li>
<li>The initial process misses some joins for two reasons: (1) because in the initial join step,
for computational performance reasons, we only test as many joins as are needed to form the
clonotypes, so some joins are not seen, and this is compounded by filtering steps that delete
putatively artifactual exact subclonotypes; (2) when we join two exact subclonotypes, and one or
both have three chains, we stop looking once we've joined them and thus do not look at all the 
chains.  To mitigate these two problems, at the time of forming clonotype tables, we recover some 
of the "lost" joins.</li>
<li>In the special case where two exact subclonotypes are joined, and both have three chains, we
apply a lower threshold for merging the "third" chain.  This threshold is that the V..J sequences
have the same length and differ at at most 10 bases.</li>
<li>We also connect onesie exact subclonotypes to other chains by matching based on exact identity 
of V..J.</li>
</ol>
This description is accurate for the current #enclone, and corresponds to changes that will appear
in Cell Ranger in a version after 6.0
</p>

<hr>

<p><b>Doublet filtering.</b>
This filtering removes some exact subclonotypes that appear to represent doublets (or possibly
higher-order multiplets).  This was introduced after Cell Ranger 5.0 and is likely to be included
in a subsequent release.</p>

<p>The algorithm works by first computing <i>pure</i> subclonotypes.  This is done by taking each
clonotype and breaking it apart according to its chain signature.  All the exact subclonotypes that
have entries for particular chains (and not entries for the other chains) are merged together to
form a pure subclonotype.</p>

<p>In the simplest case, where the clonotype has two chains, the clonotype could give rise to three
pure subclonotypes: one for the exact subclonotypes that have both chains, and one each for the
subclonotypes that have only one chain.</p>

<p>The algorithm then finds triples <code>(p0, p1, p2)</code> of pure subclonotypes, for which
the following three conditions are all satisfied:
<ul>
<li><code>p0</code> and <code>p1</code> share an identical CDR3 DNA sequence</li>
<li><code>p0</code> and <code>p2</code> share an identical CDR3 DNA sequence</li>
<li><code>p1</code> and <code>p2</code> do <i>not</i> share an identical CDR3 DNA sequence.</li>
</ul>
</p>

<p>Finally, if <code>5 * ncells(p0) <= min( ncells(p1), ncells(p2) )</code>, the entire pure 
subclonotype <code>p0</code> is deleted.  And after all these operations are completed, some of 
the original clonotypes may break up into separate clonotypes, as they may no longer be held 
together by shared chains.</p>

<p>If the argument <code>NDOUBLET</code> is supplied to #enclone, then doublet filtering is
not applied.</p>

<hr>

<p><b>Foursie filtering.</b>  
Foursie exact subclonotypes are highly enriched for cell doublets.  Deleting them all
<i>might</i> be justified, but because it is hypothetically possible that sometimes they represent 
the actual biology of single cells, we do not do this.  However we never merge them with other
exact subclonotypes, and sometimes we delete them, if we have other evidence they they are
doublets.  Specifically, for each foursie exact subclonotype, #enclone looks at each pair of two 
chains within it (with one heavy and one light, or TRB/TRA), and if the V..J sequences for those 
appear in a twosie exact subclonotype having at least ten cells, then the foursie exact 
subclonotype is deleted, no matter how many cells it has.  For example, this shows two foursie 
clonotypes that are present if the filtering is off:

<pre><code>enclone BCR=123085 CDR3=CARRYFGVVADAFDIW NFOURSIE_KILL
</code></pre>

#include pages/auto/foursie1.html

and which are deleted if the foursie filtering is on:

<pre><code>enclone BCR=123085 CDR3=CARRYFGVVADAFDIW
</code></pre>

#include pages/auto/foursie2.html

<hr>

<p><b>Weak chain filtering.</b>  If a clonotype has three or more chains, and amongst those there 
is a chain that appears in a relatively small number of cells, we delete all the cells that support
that chain.  This filter is turned off if <code>NWEAK_CHAINS</code> is specified.  The precise
condition is that the number of cells supporting the chain is at most <code>20</code>, and 
<code>8</code> times that number of cells is less than the total number of cells in the clonotype.

<br>

For the current Cell Ranger, replace <code>20</code> by <code>5</code>.  This will change at some
point after Cell Ranger 6.0.

<hr>

<p><b>Cross filtering.</b>  If multiple draws are made from the same tube of cells, and one library
made from each, yielding multiple "datasets" having the same "origin", then the clonotypes 
observed in different libraries should be statistically consistent.  Otherwise, they likely 
represent an artifact, for example, possibly resulting from fragmentation of a plasma cell.  We
apply the following test as a proxy for statistical consistency (unless <code>NCROSS</code> is
specified):
</p>

<p>
If a V..J segment appears in exactly one dataset, with frequency <code>n</code>, let 
<code>x</code> be the total number of productive pairs for that dataset, and let <code>y</code> be 
the total number of productive pairs for all datasets from the same origin.  
If <code>(x/y)^n â‰¤ 10^-6</code>, i.e. the probability that assuming even distribution, all 
instances of that V..J ended up in that one dataset, delete all the productive pairs for that 
V..J segment that do not have at least <code>100</code> supporting UMIs.
</p>

<p>This test could clearly be strengthened.</p>

<hr>

<p><b>UMI filtering.</b>  #enclone filters out B cells having low UMI counts, relative to a baseline
that is determined for each dataset, according to a
heuristic described here, unless the argument <code>NUMI</code> is supplied, to turn off that
filter.</code>

<p>The motivation for this filter is to mitigate illusory clonotype expansions arising from
fragmentation of plasma cells or other physical processes (not all fully understood).  These
processes all result in "cells" having low UMI counts, many of which do not correspond to intact 
real cells.  Illusory clonotype expansions are generally infrequent, but occasionally cluster
in individual datasets.</p>

<p>Nomenclature: for any cell, find the maximum UMI count for its heavy chains, if any, and the 
maximum for its light chains, if any.  The sum of these two maxima is denoted 
<code>umitot</code>.</p>

<p>The algorithm for this filter first establishes a baseline for the expected value of 
<code>umitot</code>, for each dataset taken individually.  To do this, all clonotypes having 
exactly one cell and exactly one heavy and light chain each are examined.  If there are less than 
<code>20</code> such cells, the filter is not applied to cells in that dataset.  Otherwise,
let <code>n_50%</code> denote the median of the <code>umitot</code> values for the dataset, and let
<code>n_10%</code> the 10th percentile.  Let
<pre><code>umin = min( n_10%, n_50% - 4 * sqrt(n_50%) )</code>.</pre>
This is the baseline <i>low</i> value for <code>umitot</code>.  The reason for having the second
part of the <code>min</code> is to prevent filtering in cases where UMI counts are sufficiently 
low that poisson variability could cause a real cell to appear fake.</p>

<p>Next we scan each clonotype having at least two cells, and delete every cell having 
<code>umitot < umin</code>, with the following qualifications:  
<ul>
<li>Let <code>k</code> be the number of cells to be deleted in clonotype having <code>n</code>
cells.  Then we require that for a binomial distribution having <code>p = 0.1</code>, the 
probability of observing <code>k</code> or more events in a sample of size <code>n</code> is 
less then <code>0.01</code>.  The more cells are flagged in a clonotype, the more likely this
test is satisfied, which is the point of the test.
</li>
<li>If <i>every</i> cell in a clonotype would be deleted, then we find its exact subclonotype 
having the highest sum for <code>umitot</code>, summing across its cells.  Then we protect from
deletion the cell in this exact subclonotype having the highest <code>umitot</code> value.  We 
do this because in general even if a clonotype expansion did not occur, there was probably at
least a single <i>bona fide</i> cell that gave rise to it.
</li>
</ul>

A better test could probably be devised that started from the expected distribution of UMI counts.
The test would trigger based on the number and improbability of low UMI counts.  The current test 
only considers the number of counts that fall below a threshold, and not their particular values.

<p>This UMI filter is carried out before most of the other filters.</p>

<hr>

<p><b>UMI ratio filtering.</b>  #enclone filters out B cells having low UMI counts, relative to
other UMI counts in a given clonotype, according to a 
heuristic described here, unless the argument <code>NUMI_RATIO</code> is supplied, to turn off that
filter.</code>

<p>First we mark a cell for possible deletion, if the VDJ UMI count for some chain of some other 
cell is at least 500 times greater than the total VDJ UMI count for the given cell.</p>

<p>Then we scan each clonotype having at least two cells, and delete every cell marked as above,
with the following qualification.  
Let <code>k</code> be the number of cells to be deleted in clonotype having <code>n</code>
cells.  Then we require that for a binomial distribution having <code>p = 0.1</code>, the 
probability of observing <code>k</code> or more events in a sample of size <code>n</code> is 
less then <code>0.01</code>.</p>

</body>
</html>
